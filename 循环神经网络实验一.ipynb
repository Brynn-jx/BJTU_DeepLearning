{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-23T15:41:21.563837Z",
     "start_time": "2025-08-23T15:41:11.357017Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from matplotlib import pyplot as plt \n",
    "import random\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, Subset, SubsetRandomSampler\n",
    "import os\n",
    "import json\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch import as_strided\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T15:41:21.985395Z",
     "start_time": "2025-08-23T15:41:21.563837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PEMS04 = np.load('./高速公路车流量数据集/PEMS04.npz')\n",
    "dataset_PEMS04 = PEMS04['data']\n",
    "print(dataset_PEMS04.shape) # 车流量，拥挤程度，车速"
   ],
   "id": "52ed3cd9371e1600",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16992, 307, 3)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 数据处理",
   "id": "9fdf445c801ab78e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T12:07:19.533565Z",
     "start_time": "2025-08-22T12:07:19.521456Z"
    }
   },
   "cell_type": "code",
   "source": "%config ServerApp.iopub_data_rate_limit = 10000000",
   "id": "a8725515eece6c2b",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T15:41:25.735009Z",
     "start_time": "2025-08-23T15:41:25.447517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaler = np.zeros(dataset_PEMS04.shape)\n",
    "print(scaler.shape)\n",
    "v_scaler = MinMaxScaler()  # 速度归一化\n",
    "o_scaler = MinMaxScaler()  # 拥挤程度归一化\n",
    "f_scaler = MinMaxScaler()  # 车流量归一化\n",
    "scaler[:,:,0] = f_scaler.fit_transform(dataset_PEMS04[:,:,0])\n",
    "scaler[:,:,1] = o_scaler.fit_transform(dataset_PEMS04[:,:,1])\n",
    "scaler[:,:,2] = v_scaler.fit_transform(dataset_PEMS04[:,:,2])\n",
    "# 划分训练数据集，验证数据集，测试数据集\n",
    "train_proportion, val_proportion, test_proportion = 0.6, 0.2, 0.2\n",
    "train_dataset = scaler[:int(train_proportion * len(dataset_PEMS04)),:,:]\n",
    "val_dataset = scaler[int(train_proportion * len(dataset_PEMS04)):int((train_proportion + val_proportion) * len(dataset_PEMS04)),:,:]\n",
    "test_dataset = scaler[int((train_proportion + val_proportion) * len(dataset_PEMS04)):,:,:]"
   ],
   "id": "e8411f6dbc30b545",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16992, 307, 3)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 采样",
   "id": "534b7b4a43d486c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T15:59:51.008952Z",
     "start_time": "2025-08-23T15:59:51.000772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TrafficDataset(Dataset):\n",
    "    def __init__(self, dataset, windows_size, predict_len=1):\n",
    "        self.dataset = dataset\n",
    "        self.windows_size = windows_size\n",
    "        self.predict_len = predict_len\n",
    "        self.T, self.N, self.F = self.dataset.shape  # 时间步，节点数，特征数\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.T - self.windows_size - self.predict_len + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 输入序列: (window_size, N, F)\n",
    "        x = self.dataset[idx:idx + self.windows_size, :, :]\n",
    "        \n",
    "        # 目标序列: (pred_len, N, F) - 预测未来pred_len个时间步\n",
    "        y = self.dataset[idx + self.windows_size:idx + self.windows_size + self.predict_len, :, :]\n",
    "        \n",
    "        # 转换为PyTorch张量并调整维度为 (序列长度, 节点数×特征数)\n",
    "        # 或者保持原始维度，在模型中处理\n",
    "        x = torch.FloatTensor(x)  # shape: (window_size, N, F)\n",
    "        y = torch.FloatTensor(y)  # shape: (pred_len, N, F)\n",
    "        x = x.reshape(self.windows_size, -1)\n",
    "        y = y.reshape(self.predict_len, -1)\n",
    "        return x, y"
   ],
   "id": "861457f8665af5e0",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 采样",
   "id": "3ea92cf059576ee0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T16:07:33.124802Z",
     "start_time": "2025-08-23T16:07:33.119260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "windows_size = 12  # 输入60分钟数据（5分钟×12）\n",
    "predict_len = 1     # 预测未来5分钟\n",
    "batch_size = 32\n",
    "train_ds = TrafficDataset(train_dataset, windows_size, predict_len)\n",
    "val_ds = TrafficDataset(val_dataset, windows_size, predict_len)\n",
    "test_ds = TrafficDataset(test_dataset, windows_size, predict_len)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ],
   "id": "49230f5d1bd3d028",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T16:07:34.291017Z",
     "start_time": "2025-08-23T16:07:34.283629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for x, y in test_loader:\n",
    "    print(y[-1, :, :].shape)\n",
    "    break"
   ],
   "id": "111d8dd3db79a2b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 921])\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T16:15:26.937123Z",
     "start_time": "2025-08-23T16:15:26.922982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluating(model, dataloader, loss_fct):\n",
    "    loss_list = []\n",
    "    mae_list = []\n",
    "    label_list = []\n",
    "    for datas, labels in dataloader:\n",
    "        datas = datas.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels[batch_size, -1]\n",
    "        # 前向计算\n",
    "        hidden, logits = model(datas)\n",
    "        loss = loss_fct(logits[-1, :, :], labels)         # 验证集损失\n",
    "        loss_list.append(loss.item())\n",
    "        mae = torch.mean(torch.abs(labels - logits[-1, :, :]))\n",
    "        mae_list.append(mae.item())\n",
    "        \n",
    "    return np.mean(loss_list), np.mean(mae_list)\n"
   ],
   "id": "4ef2c7509f576a57",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T16:11:49.914609Z",
     "start_time": "2025-08-23T16:11:49.904237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EarlyStopCallback:\n",
    "    def __init__(self, patience=5, min_delta=0.01):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_metric = -1\n",
    "        self.counter = 0\n",
    "        \n",
    "    def __call__(self, metric):\n",
    "        if metric >= self.best_metric + self.min_delta:\n",
    "            # update best metric\n",
    "            self.best_metric = metric\n",
    "            # reset counter \n",
    "            self.counter = 0\n",
    "        else: \n",
    "            self.counter += 1\n",
    "            \n",
    "    @property\n",
    "    def early_stop(self):\n",
    "        return self.counter >= self.patience\n"
   ],
   "id": "599b20eefcc346d6",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T16:11:51.891351Z",
     "start_time": "2025-08-23T16:11:51.882390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyRnn(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MyRnn, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.w_h = nn.Parameter(torch.randn(input_size, self.hidden_size))\n",
    "        self.u_h = nn.Parameter(torch.randn(self.hidden_size, self.hidden_size))\n",
    "        self.b_h = nn.Parameter(torch.zeros(self.hidden_size))\n",
    "        \n",
    "        self.w_y = nn.Parameter(torch.randn(self.hidden_size, self.output_size))\n",
    "        self.b_y = nn.Parameter(torch.zeros(self.output_size))\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    \n",
    "    def init_weights(self):\n",
    "        for param in self.parameters():\n",
    "            if param.dim() > 1:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "        h = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "        y_list = []\n",
    "        for i in range(seq_len):\n",
    "            h = self.tanh(torch.matmul(x[:,i,:], self.w_h) + torch.matmul(h, self.u_h) + self.b_h)\n",
    "            y = self.relu(torch.matmul(h, self.w_y) + self.b_y)\n",
    "            y_list.append(y)\n",
    "        \n",
    "        return h, y_list"
   ],
   "id": "e4f120af687ce331",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T16:13:02.946345Z",
     "start_time": "2025-08-23T16:13:02.933182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练\n",
    "def training_manual_rnn(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    epoch, \n",
    "    loss_fct, \n",
    "    optimizer, \n",
    "    early_stop_callback=None,\n",
    "    eval_step=100,\n",
    "    ):\n",
    "    record_dict = {\n",
    "        \"train\": [],\n",
    "        \"val\": []\n",
    "    }\n",
    "    \n",
    "    global_step = 0\n",
    "    model.train()\n",
    "    with tqdm(total=epoch * len(train_loader)) as pbar:\n",
    "        for epoch_id in range(epoch):\n",
    "            # training\n",
    "            for datas, labels in train_loader:\n",
    "                datas = datas.to(device)\n",
    "                labels = labels.to(device)\n",
    "                labels = labels[batch_size, -1]\n",
    "                # 梯度清空\n",
    "                optimizer.zero_grad()\n",
    "                # 模型前向计算\n",
    "                hidden, logits = model(datas)\n",
    "                # 计算损失\n",
    "                loss = loss_fct(logits[-1, :, :], labels)\n",
    "                # 梯度回传\n",
    "                loss.backward()\n",
    "                # 调整优化器，包括学习率的变动等\n",
    "                optimizer.step()\n",
    "                mae = torch.mean(torch.abs(logits[-1, :, :] - labels))\n",
    "                loss = loss.cpu().item() # 计算损失\n",
    "                # record\n",
    "                \n",
    "                record_dict[\"train\"].append({\n",
    "                    \"loss\": loss, \"mae\": mae.detach().numpy(), \"step\": global_step # 记录每一步的损失和准确率\n",
    "                })\n",
    "                \n",
    "                # evaluating\n",
    "                if global_step % eval_step == 0:\n",
    "                    model.eval()\n",
    "                    val_loss, val_mae = evaluating(model, val_loader, loss_fct)\n",
    "                    record_dict[\"val\"].append({\n",
    "                        \"loss\": val_loss, \"mae\": val_mae, \"step\": global_step\n",
    "                    })\n",
    "                    model.train()\n",
    "\n",
    "\n",
    "                    if early_stop_callback is not None:\n",
    "                        early_stop_callback(-val_mae)\n",
    "                        if early_stop_callback.early_stop:\n",
    "                            print(f\"Early stop at epoch {epoch_id} / global_step {global_step}\")\n",
    "                            return record_dict\n",
    "                    \n",
    "                # udate step\n",
    "                global_step += 1\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({\"epoch\": epoch_id})\n",
    "        \n",
    "    return record_dict"
   ],
   "id": "8759e57e388af216",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "epoch = 30\n",
    "model_manual_rnn = MyRnn(307 * 3, 307 * 3 * 5, 307 * 3)\n",
    "loss_fct_manual_rnn = nn.MSELoss()\n",
    "optimizer_manual_rnn = torch.optim.Adam(model_manual_rnn.parameters(), lr=0.001)\n",
    "early_stop_callback = EarlyStopCallback(patience=5)\n",
    "model_manual_rnn = model_manual_rnn.to(device)\n",
    "record_manual_vehicle = training_manual_rnn(\n",
    "    model_manual_rnn,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    epoch,\n",
    "    loss_fct_manual_rnn,\n",
    "    optimizer_manual_rnn,\n",
    "    early_stop_callback=early_stop_callback,\n",
    "    eval_step=500\n",
    "    )"
   ],
   "id": "ab5dd80a44f54fea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
