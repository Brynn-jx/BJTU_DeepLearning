{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-10T13:31:52.911564Z",
     "start_time": "2025-08-10T13:31:52.905584Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from matplotlib import pyplot as plt \n",
    "import random\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, Subset, SubsetRandomSampler\n",
    "import os\n",
    "import json\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "from torchvision.datasets import ImageFolder"
   ],
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 数据处理",
   "id": "c8cf204e5651c053"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 车辆分类数据集",
   "id": "590475215ee9ad75"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T14:10:11.118660Z",
     "start_time": "2025-08-10T14:10:11.100206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class_name = [\n",
    "    \"bus\",\n",
    "    \"car\",\n",
    "    \"truck\"\n",
    "]\n",
    "PATH_CAR=\"./车辆分类数据集/车辆分类数据集\"\n",
    "# 变成dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # 将PIL图像转为Tensor [C, H, W]\n",
    "])\n",
    "dataset_car=ImageFolder(PATH_CAR, transform=transform)\n",
    "image, label=dataset_car[0]\n",
    "print(image.shape)\n",
    "\n",
    "def split_dataset(root_path, test_size=0.2, random_seed=42):\n",
    "    dataset_car=ImageFolder(PATH_CAR)\n",
    "    # 获取每个类别的样本索引\n",
    "    class_idx={}\n",
    "    for idx, (_, label) in enumerate(dataset_car.imgs):\n",
    "        if label not in class_idx:\n",
    "            class_idx[label]=[]\n",
    "        class_idx[label].append(idx)\n",
    "    \n",
    "    # 按类别划分训练集和测试集\n",
    "    train_indices, test_indices = [], []\n",
    "    for label, indices in class_idx.items():\n",
    "        idx_train, idx_test = train_test_split(\n",
    "            indices, \n",
    "            test_size=test_size, \n",
    "            random_state=random_seed,\n",
    "            shuffle=True\n",
    "        )\n",
    "        train_indices.extend(idx_train)\n",
    "        test_indices.extend(idx_test)\n",
    "    return train_indices, test_indices\n"
   ],
   "id": "e705d2a31c211701",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 120, 85])\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T14:10:52.510856Z",
     "start_time": "2025-08-10T14:10:49.045251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_mean_std(dataset_path, img_size=(224, 224), batch_size=32):\n",
    "    \"\"\"\n",
    "    计算图像数据集的均值和标准差\n",
    "    :param dataset_path: 数据集路径（需为ImageFolder格式）\n",
    "    :param img_size: 统一调整的图像尺寸\n",
    "    :param batch_size: 批量处理大小\n",
    "    :return: (mean, std) 各通道的均值和标准差\n",
    "    \"\"\"\n",
    "    # 预处理：调整尺寸 + 转为Tensor\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.ToTensor()  # 自动缩放到[0,1]\n",
    "    ])\n",
    "    \n",
    "    # 加载数据集\n",
    "    dataset = ImageFolder(dataset_path, transform=transform)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # 初始化统计变量\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    nb_samples = 0.\n",
    "    \n",
    "    # 遍历数据集计算\n",
    "    for data, _ in tqdm(loader):\n",
    "        batch_samples = data.size(0)\n",
    "        data = data.view(batch_samples, data.size(1), -1)  # 展平H,W维度\n",
    "        mean += data.mean(2).sum(0)  # 各通道均值求和\n",
    "        std += data.std(2).sum(0)    # 各通道标准差求和\n",
    "        nb_samples += batch_samples\n",
    "    \n",
    "    # 计算全局均值和标准差\n",
    "    mean /= nb_samples\n",
    "    std /= nb_samples\n",
    "    return mean.tolist(), std.tolist()\n",
    "\n",
    "mean, std = compute_mean_std(PATH_CAR)\n",
    "print(f\"均值: {mean}\")  # 例如 [0.485, 0.456, 0.406]\n",
    "print(f\"标准差: {std}\")  # 例如 [0.229, 0.224, 0.225]"
   ],
   "id": "6ade5809e3a41a47",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "735c185d5798411fa9744e056e8a2683"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "均值: [0.4101674556732178, 0.4220322370529175, 0.4358880817890167]\n",
      "标准差: [0.19289539754390717, 0.19039973616600037, 0.1875486969947815]\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T14:13:45.613291Z",
     "start_time": "2025-08-10T14:13:45.581334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((80, 100)),\n",
    "    transforms.RandomRotation(5), \n",
    "    transforms.ToTensor(),   #转为Tensor并自动缩放到0，1\n",
    "    transforms.Lambda(lambda x: x + torch.randn_like(x) * 0.005),  # 提前加噪声\n",
    "    transforms.Normalize(mean=[0.410, 0.422, 0.435], std=[0.193, 0.190, 0.187]),\n",
    "])\n",
    "\n",
    "# 加载完整数据集（应用预处理）\n",
    "dataset = ImageFolder(root=PATH_CAR, transform=transform)\n",
    "\n",
    "# 划分训练集和测试集（测试集占20%）\n",
    "train_idx, test_idx = split_dataset(PATH_CAR, test_size=0.2)\n",
    "\n",
    "# 创建SubsetRandomSampler（自动打乱）\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# 创建DataLoader\n",
    "train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler)\n",
    "test_loader = DataLoader(dataset, batch_size=32, sampler=test_sampler)"
   ],
   "id": "ffaefcf989312c27",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T14:16:48.699487Z",
     "start_time": "2025-08-10T14:16:48.627791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(train_loader.dataset)\n",
    "for data, _ in train_loader:\n",
    "    print(data.shape)\n",
    "    break"
   ],
   "id": "12b0c56cfbbcbf32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 1357\n",
      "    Root location: ./车辆分类数据集/车辆分类数据集\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(80, 100), interpolation=bilinear, max_size=None, antialias=True)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.41, 0.422, 0.435], std=[0.193, 0.19, 0.187])\n",
      "           )\n",
      "torch.Size([32, 3, 80, 100])\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 手写二维卷积",
   "id": "76d7b692793e40e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T10:03:36.317918Z",
     "start_time": "2025-08-10T10:03:36.312678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 根据im2col变为矩阵乘法\n",
    "def split_by_strides_np(X, kh, kw, s):\n",
    "    N, C, H, W = X.shape\n",
    "    oh = (H - kh) // s + 1\n",
    "    ow = (W - kw) // s + 1\n",
    "    print(X.strides)\n",
    "    strides = (*X.strides[:-2], X.strides[-2]*s, X.strides[-1]*s, *X.strides[-2:])\n",
    "    print(strides)\n",
    "    A = as_strided(X, shape=(N,C,oh,ow,kh,kw), strides=strides)\n",
    "    return A"
   ],
   "id": "3cc0277f6c5e3a20",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "np.tensordot可以指定对应的轴相乘，相乘完的轴就可以认为没了，然后将剩下的轴拼在一起\n",
    "在使用的时候只要弄懂每个轴是什么物理意义，然后知道想要输出的形状是什么样子的就行了\n",
    "\n",
    "例如这里A.shape(N,C,oh,ow,kh,kw),kernel.shape(n,c,kh,kw)我想要输出的样子是(N, n, oh, ow)所以axes[(1,4,5), (1,2,3)]\n",
    "\n",
    "将C，c；kh，kh；kw，kw相乘，拼接成了(N,oh,ow,n)的形状，然后使用transpose调整一下位置即可"
   ],
   "id": "2895d734c0f488f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T10:03:38.143312Z",
     "start_time": "2025-08-10T10:03:38.130399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def conv_np(X, kernel, stride=1, padding=0):\n",
    "    n, c, kh, kw = kernel.shape\n",
    "    A =split_by_strides_np(X, kh, kw, stride)\n",
    "    res=np.tensordot(A, kernel, axes=[(1,4,5), (1,2,3)])\n",
    "    res = res.transpose((0,3,1,2))\n",
    "    return  res"
   ],
   "id": "9d628bb447ce0a56",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T10:03:39.955169Z",
     "start_time": "2025-08-10T10:03:39.888985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X1 = np.arange(1,19, dtype=np.int32).reshape(1, 2,3,3)\n",
    "kernel = np.arange(1,9, dtype=np.int32).reshape(1, 2,2,2)\n",
    "res = conv_np(X1, kernel)\n",
    "print(res)"
   ],
   "id": "fa6f9efff5fb7c82",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 36, 12, 4)\n",
      "(72, 36, 12, 4, 12, 4)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "as_strided(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[47]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m X1 = np.arange(\u001B[32m1\u001B[39m,\u001B[32m19\u001B[39m, dtype=np.int32).reshape(\u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m,\u001B[32m3\u001B[39m,\u001B[32m3\u001B[39m)\n\u001B[32m      2\u001B[39m kernel = np.arange(\u001B[32m1\u001B[39m,\u001B[32m9\u001B[39m, dtype=np.int32).reshape(\u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m,\u001B[32m2\u001B[39m,\u001B[32m2\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m res = \u001B[43mconv_np\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkernel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[38;5;28mprint\u001B[39m(res)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[46]\u001B[39m\u001B[32m, line 3\u001B[39m, in \u001B[36mconv_np\u001B[39m\u001B[34m(X, kernel, stride, padding)\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mconv_np\u001B[39m(X, kernel, stride=\u001B[32m1\u001B[39m, padding=\u001B[32m0\u001B[39m):\n\u001B[32m      2\u001B[39m     n, c, kh, kw = kernel.shape\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m     A =\u001B[43msplit_by_strides_np\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkh\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstride\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m     res=np.tensordot(A, kernel, axes=[(\u001B[32m1\u001B[39m,\u001B[32m4\u001B[39m,\u001B[32m5\u001B[39m), (\u001B[32m1\u001B[39m,\u001B[32m2\u001B[39m,\u001B[32m3\u001B[39m)])\n\u001B[32m      5\u001B[39m     res = res.transpose((\u001B[32m0\u001B[39m,\u001B[32m3\u001B[39m,\u001B[32m1\u001B[39m,\u001B[32m2\u001B[39m))\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[45]\u001B[39m\u001B[32m, line 9\u001B[39m, in \u001B[36msplit_by_strides_np\u001B[39m\u001B[34m(X, kh, kw, s)\u001B[39m\n\u001B[32m      7\u001B[39m strides = (*X.strides[:-\u001B[32m2\u001B[39m], X.strides[-\u001B[32m2\u001B[39m]*s, X.strides[-\u001B[32m1\u001B[39m]*s, *X.strides[-\u001B[32m2\u001B[39m:])\n\u001B[32m      8\u001B[39m \u001B[38;5;28mprint\u001B[39m(strides)\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m A = \u001B[43mas_strided\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43mN\u001B[49m\u001B[43m,\u001B[49m\u001B[43mC\u001B[49m\u001B[43m,\u001B[49m\u001B[43moh\u001B[49m\u001B[43m,\u001B[49m\u001B[43mow\u001B[49m\u001B[43m,\u001B[49m\u001B[43mkh\u001B[49m\u001B[43m,\u001B[49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrides\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstrides\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m A\n",
      "\u001B[31mTypeError\u001B[39m: as_strided(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T10:45:56.949719Z",
     "start_time": "2025-08-10T10:45:56.930683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import as_strided\n",
    "\n",
    "def split_by_strides(X, kh, kw, s):\n",
    "    N, C, H, W = X.shape\n",
    "    oh = (H - kh) // s + 1\n",
    "    ow = (W - kw) // s + 1\n",
    "    \n",
    "    # 计算PyTorch张量的stride\n",
    "    stride = list(X.stride())\n",
    "    strides = (stride[0], stride[1], \n",
    "               stride[2]*s, stride[3]*s, \n",
    "               stride[2], stride[3])\n",
    "    \n",
    "    A = as_strided(X, size=(N, C, oh, ow, kh, kw), \n",
    "                  stride=strides)\n",
    "    return A\n",
    "\n",
    "def conv(X, kernel, stride=1, padding=0):\n",
    "    if padding > 0:\n",
    "        X = F.pad(X, (padding, padding, padding, padding))\n",
    "    \n",
    "    n, c, kh, kw = kernel.shape\n",
    "    A = split_by_strides(X, kh, kw, stride)\n",
    "    \n",
    "    # 使用einsum实现张量收缩\n",
    "    res = torch.einsum('nchwkl,ockl->nohw', A, kernel)\n",
    "    return res"
   ],
   "id": "4c97105461a1d33e",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T10:49:20.964274Z",
     "start_time": "2025-08-10T10:49:20.954232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X1 = torch.randn((1, 2, 3, 3))\n",
    "kernel = torch.randn((2, 2, 2, 2))\n",
    "print(conv(X1, kernel))"
   ],
   "id": "197ca972ddfdc69b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-10.4530,  -4.5276],\n",
      "          [  4.6923,   5.0751]],\n",
      "\n",
      "         [[  8.4299,   1.3304],\n",
      "          [  5.3363,   7.8171]]]])\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T10:46:00.187976Z",
     "start_time": "2025-08-10T10:46:00.181556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyConv2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(MyConv2D, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size=(kernel_size, kernel_size)\n",
    "        self.weight = nn.Parameter(torch.randn((out_channels, in_channels) + kernel_size))\n",
    "        self.bias = nn.Parameter(torch.randn((out_channels ,1 ,1)))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return conv(x, self.weight, self.stride, self.padding) + self.bias"
   ],
   "id": "37f0a694967283fe",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T10:48:53.275128Z",
     "start_time": "2025-08-10T10:48:53.266624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "my_conv = MyConv2D(2, 2, 2)\n",
    "X = torch.randn((1, 2, 3, 3))\n",
    "print(my_conv.forward(X))"
   ],
   "id": "59b790419d3421dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.0390,  1.8059],\n",
      "          [ 2.6420,  1.2737]],\n",
      "\n",
      "         [[-2.7758, -1.6841],\n",
      "          [ 2.3810, -2.4902]]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c15ce776cef8fd39"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
